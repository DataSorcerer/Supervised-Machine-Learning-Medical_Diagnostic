{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning: Model Training and Evaluation\n",
    "\n",
    "### Data loading and exploratory analysis\n",
    "\n",
    "1.\tThe Comma Separated Values (CSV) format data present in illness.txt file was loaded into a pandas data structure called data frame   \n",
    "2.\tSince, the data is column wise, it needed to be transposed to row wise representation.   \n",
    "3.\tAlso, the columns were assigned names to ease accessing any particular column for operations in future. Finally, first few rows were displayed to check if file is loaded correctly  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plasma_glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>test_result</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>num_pregnancies</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.692</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.527</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.597</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.725</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  plasma_glucose  bp  test_result skin_thickness num_pregnancies insulin  \\\n",
       "0            122  64            1             32               1     156   \n",
       "1             80  74            0             11               1      60   \n",
       "2            100  70            0             26               0      50   \n",
       "3            119  64            0             18               0      92   \n",
       "4            162  76            1             56               0     100   \n",
       "\n",
       "    bmi pedigree age  \n",
       "0  35.1    0.692  30  \n",
       "1    30    0.527  22  \n",
       "2  30.8    0.597  21  \n",
       "3  34.9    0.725  23  \n",
       "4  53.2    0.759  25  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #load pandas library\n",
    "\n",
    "#Read CSV data from 'illness.txt' into a pandas data frame and transpose it\n",
    "dfMedicalTest = pd.read_csv('illness.txt', header=None).T\n",
    "#Assign column names\n",
    "dfMedicalTest.columns = [\"plasma_glucose\", \"bp\", \"test_result\", \"skin_thickness\", \"num_pregnancies\", \"insulin\", \"bmi\", \"pedigree\", \"age\"]\n",
    "dfMedicalTest.head(n = 3) #display first 3 rows\n",
    "\n",
    "#Replace string labels 'positive/ negative' with 1/0\n",
    "dfMedicalTest.replace('positive', 1, inplace=True)\n",
    "dfMedicalTest.replace('negative', 0, inplace=True)\n",
    "dfMedicalTest.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if dataframe contains any missing value\n",
    "dfMedicalTest.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.313830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.464666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_result\n",
       "count   376.000000\n",
       "mean      0.313830\n",
       "std       0.464666\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMedicalTest.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into train/ test and validation set\n",
    "First, we split data into:   \n",
    "(a) training/ test data and   \n",
    "(b) Validation data (to be used after training/ testing is done)   \n",
    "**Note:** It is extremely important that trained model is validated with some previously held out unseen dataset, in order to evalaute the unbiased performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Lock aside a 1/3rd of data (randomly sampled) for validation after training and testing the model\n",
    "dfMedicalTest_train, dfMedicalTest_validate = np.split(dfMedicalTest.sample(frac=1), [int((2/3)*len(dfMedicalTest))])\n",
    "X_train_data = np.array(dfMedicalTest_train.drop([\"test_result\"], 1)) #Store all features data for training set\n",
    "y_train_target = np.array(dfMedicalTest_train[\"test_result\"])         #Store only target class data for training set\n",
    "X_validate_data = np.array(dfMedicalTest_validate.drop([\"test_result\"], 1)) #Store all features data for validation set\n",
    "y_validate_target = np.array(dfMedicalTest_validate[\"test_result\"])   #Store only target class data for validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training machine learning models\n",
    "\n",
    "#### Classifier 1: K-nearest neighbours (kNN)\n",
    "\n",
    "Nearest neighbours classifier learns about training data through induction. It simply stores the training data that it encounters and does not construct a target function beforehand. Once a new instance of data is presented, its  relationship with existing information is evaluated (often in terms of distance) and then the target function is assigned an appropriate value. In fact, such delayed processing of data is also known as lazy learning and kNN is one of the simplest exponent of this variant. Key steps for implementing simple version of kNN are:   \n",
    "1. *__Training: __* This phase involves identifying class label(s) and features (attributes) which are used to predict them and simply storing them.\n",
    "2. *__Parameter Selection:__* The value of parameter ‘k’ depends upon data to be classified. Generally, it is an odd number for binary classification problems in order to avoid conflicts in case of neighbours majority vote. Also, it is observed that higher the value of k (limited range), lesser tends to be the effect of noise on the model.\n",
    "3.\t*__Classification:__* A distance metric such as Euclidean distance is used to calculate proximity of test query with training data. Since, different features have different measures, it is better to normalize all of them to same scale in order to avoid one feature dominating distance metrics. A vote of k nearest neighbour is obtained and value of test class label is decided by the class value of majority of neighbours.   \n",
    "Type of distance metrics:   \n",
    "i. Manhattan distance   \n",
    "ii. Euclidean distance   \n",
    "iii. Hamming distance   \n",
    "iv. Cosine distance   \n",
    "Presenting unseen test instance to 9-NN classification model trained with 350 instances of illness data:   \n",
    "<img src=\"images/kNN.png\">\n",
    "\n",
    "*Scenarios where k-Nearest Neighbours classifier could be used:*   \n",
    "•\tWhen there are large number of instances available to learn and decision boundaries can get irregular\n",
    "•\tDimensions in data are limited to a small or moderate number (ideally < 20)\n",
    "\n",
    "**Applications:**   \n",
    "Highly successful in classifying handwritten digits, satellite image scenes and heart EKG patterns\n",
    "\n",
    "#### Classifier 2: Logistic Regression\n",
    "\n",
    "   Logistic Regression is one of the important statistical modelling techniques used to describe relationship between one or more independent variables (predictors/ explanatory variables) and one or more discrete valued output (dependent/ response) variables. The binomial (binary) logistic regression technique suits well our task of modelling a classifier with illness data for predicting whether the test results would be positive or negative (0 or 1).\n",
    " This classifier tries to build a hypothesis function to try to predict probability (or specifically odds) of a particular instance belonging to class 1 (positive/ true/ yes and so on) and not belonging to class 0 (negative/ false/ no, etc.).   \n",
    " \n",
    " <img src=\"images/LR1.png\">\n",
    " \n",
    " Since, we are not dealing with continuous outcomes, using hypothesis function similar to linear regression produces non-useful results. Also, the value of P(1|x) is observed to change gradually with change in x. In such a case, a logistic (also known as sigmoid) function instead of a linear function perfectly represents the relationship between hypothesis and expected value. Thus, hypothesis function can be formulated as:   \n",
    "<img src=\"images/LR2.png\">    \n",
    "<img src=\"images/LR3.png\">   \n",
    "<img src=\"images/LR4.png\">      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction & Evaluation\n",
    " - We use kNN and LogisticRegression implementations from Python scikit Learn package\n",
    " - 10-fold stratified cross validation is used so that each fold has similar distribution of +ve/ -ve classes as in complete data.    \n",
    " <img src=\"images/testdata.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over Stratified 10-fold validation:\n",
      "1. k Nearest Neighbours =  0.768076923077 \n",
      "2. Logistic Regression =  0.747935897436 \n",
      "\n",
      "--------------------------------------------------------\n",
      "Confusion Matrix, Sensitivity (Recall) and Specificity: \n",
      "--------------------------------------------------------\n",
      "1. k Nearest Neighbours\n",
      " [[75  6]\n",
      " [27 18]] \tSensitivity =  0.735294117647 \tSpecificity =  0.75 \n",
      "\n",
      "2. Logistic Regression\n",
      " [[75  6]\n",
      " [26 19]] \tSensitivity =  0.742574257426 \tSpecificity =  0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, linear_model #Contains class definitions for k-Nearest neighbours and Logistic Regression\n",
    "from sklearn.model_selection import StratifiedKFold #to perform stratified 10 fold cross-validation\n",
    "import matplotlib.pyplot as plt   #to plot ROC curves\n",
    "from sklearn.metrics import confusion_matrix #to construct confusion matrix after training/ testing models\n",
    "\n",
    "skFold_scores_Logistic = []; skFold_scores_kNN = []  #to store accuracy scores across 10 folds and calculate their mean\n",
    "stratified_k_folds = StratifiedKFold(10, random_state=0) #Create 10 stratified folds\n",
    "\n",
    "LogisticClassifier = linear_model.LogisticRegression()  \n",
    "kNNclassifier = neighbors.KNeighborsClassifier(n_neighbors=9) #set number of nearest neighbours to 9\n",
    "#iterate over 10 folds while fitting the models\n",
    "for train_index, test_index in stratified_k_folds.split(X_train_data,y_train_target):\n",
    "    kNNclassifier.fit(X_train_data[train_index], y_train_target[train_index]) #train kNN classifer model\n",
    "    skFold_scores_kNN.append(kNNclassifier.score(X_train_data[test_index], y_train_target[test_index])) #store accuracies\n",
    "    \n",
    "for train_index, test_index in stratified_k_folds.split(X_train_data,y_train_target):\n",
    "    LogisticClassifier.fit(X_train_data[train_index], y_train_target[train_index]) #train Logistic Regression model\n",
    "    skFold_scores_Logistic.append(LogisticClassifier.score(X_train_data[test_index], y_train_target[test_index]))\n",
    "\n",
    "#Unlock validation dataset and test our models' prediction on unseen instances\n",
    "y_validate_predicted_Logistic = LogisticClassifier.predict(X_validate_data)\n",
    "y_validate_predicted_kNN = kNNclassifier.predict(X_validate_data)\n",
    "\n",
    "#Construct confusion matrix by comparing actual target values with respective predicted values\n",
    "confusion_matrix_kNN = confusion_matrix(y_validate_target, y_validate_predicted_kNN)\n",
    "confusion_matrix_Logistic = confusion_matrix(y_validate_target, y_validate_predicted_Logistic)\n",
    "#get true positive, false positive, false negative & true negative values from confusion matrix\n",
    "tp_kNN, fp_kNN, fn_kNN, tn_kNN = confusion_matrix_kNN.ravel()\n",
    "tp_Logistic, fp_Logistic, fn_Logistic, tn_Logistic = confusion_matrix_Logistic.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation\n",
    "\n",
    "Confusion matrix, True positive rate, False positive rate, Sensitivity, Specificity and ROC curves are used to evaluate the performance of two models. \n",
    "#### Accuracy, Confusion matrix, Specificity and Sensitivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over Stratified 10-fold validation:\n",
      "1. k Nearest Neighbours =  0.768076923077 \n",
      "2. Logistic Regression =  0.747935897436 \n",
      "\n",
      "--------------------------------------------------------\n",
      "Confusion Matrix, Sensitivity (Recall) and Specificity: \n",
      "--------------------------------------------------------\n",
      "1. k Nearest Neighbours\n",
      " [[75  6]\n",
      " [27 18]] \n",
      "\n",
      "2. Logistic Regression\n",
      " [[75  6]\n",
      " [26 19]] \tSensitivity =  0.742574257426 \tSpecificity =  0.76\n"
     ]
    }
   ],
   "source": [
    "#Print metrics for kNN and Logistic Regression Classifers\n",
    "print(\"Accuracy over Stratified 10-fold validation:\\n1. k Nearest Neighbours = \", \\\n",
    "      np.mean(np.abs(skFold_scores_kNN)),\"\\n2. Logistic Regression = \", \\\n",
    "      np.mean(np.abs(skFold_scores_Logistic)), \\\n",
    "      \"\\n\\n--------------------------------------------------------\\nConfusion Matrix, \\\n",
    "      Sensitivity (Recall) and Specificity: \\n---------------------------------------------------\\\n",
    "      -----\\n1. k Nearest Neighbours\\n\", confusion_matrix_kNN,\"\\n\\n2. Logistic Regression\\n\", \\\n",
    "      confusion_matrix_Logistic, \"\\tSensitivity = \",tp_Logistic/(tp_Logistic + fn_Logistic),\\\n",
    "      \"\\tSpecificity = \",tn_Logistic/(tn_Logistic + fp_Logistic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curves\n",
    "\n",
    " - **Calculate Probability Estimates:** ROC curves are plotted using true positive and false positive rates which require comparing probabilities of predicting positive value with actual target value. Hence, probability estimates of predictions are calculated for both models using the previously held out test dataset.\n",
    " - **Compute TPR, FPR, Thresholds:** ‘roc_curve’ function computes the false positive rates, true positive rates and threshold values for binary classifiers. The increasing FPR and TPR values are calculated with decreasing threshold values on decision function. ROC Curves are a measure of trade-off between Sensitivity and Specificity typically for a binary classifier   \n",
    " <img src=\"images/Rates.png\">      \n",
    "- TPR and FPR are calculated at various threshold values starting from highest threshold to lowest. If the classifier score is greater than a threshold value, a positive label value is predicted; and if actual value is positive, it is considered as TP else FP. For increase in TPR, ROC curve moves along Y-axis and with increase in FPR, along X-axis. For e.g. consider 5 instances of test data with threshold value of 0.52. Here is the plot:   \n",
    " <img src=\"images/Calculation.png\">    \n",
    " - **Area Under Curve (AUC):** Area under Sensitivity vs. Fallout curve denotes the probability that the machine learning classification model will predict a random instance as positive than negative. It is also known as C-Score. In scikit-learn library, it can be calculated using ‘metrics.auc’ function which essentially computes it using trapezoidal rule.\n",
    " - **Plot ROC Curve:** Plotted ROC curve using Matplotlib library and setting Y-axis as Sensitivity (Recall/ True Positive Rate) and X-axis as 1 - Specificity (Fall out rate/ False positive rate). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwnEcx8mR/wfEBN5lQ0N/hQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x266361307f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Predict probability estimates of the positive class on held out data using kNN classifier\n",
    "predictions_kNN = kNNclassifier.predict_proba(X_validate_data)[:,1]\n",
    "#Compute false positive, true positive rates, threshold values with actual label values and predicted probabilites\n",
    "fpr_kNN, tpr_kNN, threshold_kNN = metrics.roc_curve(y_validate_target, predictions_kNN)\n",
    "#Compute value of Area Under Curve for kNN classifier\n",
    "roc_auc_kNN = metrics.auc(fpr_kNN, tpr_kNN)\n",
    "\n",
    "#Predict probability estimates of the positive class on held out data using Logistic Regression classifier\n",
    "predictions_LR = LogisticClassifier.predict_proba(X_validate_data)[:,1]\n",
    "#Compute false positive, true positive rates, threshold values with actual label values and predicted probabilites\n",
    "fpr_LR, tpr_LR, threshold_LR = metrics.roc_curve(y_validate_target, predictions_LR)\n",
    "#Compute value of Area Under Curve for Logistic Regression classifier\n",
    "roc_auc_LR = metrics.auc(fpr_LR, tpr_LR)\n",
    "\n",
    "#Plot ROC curves for kNN and Logistic Regression classifiers using respective tpr and fpr\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_kNN, tpr_kNN, 'b', label = 'kNN AUC = %0.2f' % roc_auc_kNN)\n",
    "plt.plot(fpr_LR, tpr_LR, 'b', label = 'Logistic AUC = %0.2f' % roc_auc_LR, color='orange')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--') #Plot diagonal\n",
    "#Fit plot exactly between [0, 0] and [1, 1]\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "**Based on ROC curves:**   \n",
    "Some of the significant observations that can be made from above ROC curves are:\n",
    "1.\t**__Better than random classifier: __**\n",
    "\n",
    "      The points on diagonal represent predictions by a random guessing classifier. The diagonal segregates the ROC space into regions with prediction better and worse than random guessing. The points lying above this ‘line of no-discrimination’ are considered to be better classifiers due to low FPR and high TPR. In our case, ROC curves of both the classifiers are much in the top region which points towards better than random guess.\n",
    "\n",
    "2.\t**__Logistic Regression Classifier performed better than kNN Classifier (higher AUC):__** \n",
    "\n",
    "      It is seen from the graph that, higher the number of points in top left corner, higher is the TPR (Sensitivity) and lower is the FPR (higher Specificity). So, a curve passing through these points would have a higher area under it. Higher Area Under Curve (AUC) denotes that a model correctly predicts a positive instance with high confidence (assigns high probability to true positive cases). In our case, we see that AUC for Logistic Regression classifier (0.82) is higher than that for kNN (0.76). Considering that ideal classifier has AUC = 1, and Logistic regression ROC curve seems to be dominating towards 1 and thus is better when tested with this randomly sampled 1/3rd of dataset (validation set). Result is likely to vary with different random set.\n",
    "\n",
    "3.\t**__Determination of Optimal Cut-off value (Threshold):__**\n",
    "\n",
    "The purpose of training classifiers over illness dataset is to predict where medical test results are positive or negative. Hence, it becomes imperative that we have high Sensitivity as well as Specificity. i.e. less number of false negatives and high number of true positives is much desired. As we see in the graph alongside, threshold values of classifiers at points shown yield highest specificity as well as sensitivity. These points are nearest to (1, 1) i.e. highest specificity as well as sensitivity and are most likely to correctly predict true positives.   \n",
    "   \n",
    "<img src=\"images/Threshold.png\">      \n",
    "\n",
    "4.\t**__Trade-off between Sensitivity and Specificity:__**\n",
    "\n",
    "In case of our graphs, we see curve for Logistic Regression grazing top axis and thus better at predicting true positives and less false negatives (better sensitivity than specificity). Generally, in situations where high sensitivity (more true positives) is desired over specificity, we seek ROC curve skewed more nearer to top axis and in cases where low false positives (high specificity) are required, a skew towards left axis is preferred. In case of medical test like this, false negatives can be fatal and thus high recall is desirous.\n",
    "\n",
    "#### Comparing kNN and Logistic regression performances\n",
    "Comparing model performances on the basis of following criteria:\n",
    "\n",
    "1.\t**__Misclassification Error:__** Both the classifiers with current selection of parameters perform almost similarly on accuracy metric. Std. Dev. suggests low variance in findings\n",
    "2.\t**__Confusion matrix:__** Since, the models predict medical test results, sensitivity (recall) and specificity are more relevant measures than accuracy as low sensitivity would mean less true positives and more false negatives which could have adverse consequences for the patients. Logistic regression performs slightly better here.\n",
    "3.\t**__Logarithmic Loss:__** Logistic regression reports a better log-loss value suggesting high confidence in correctly classifying positive cases whereas kNN appears more confident in incorrectly classifying them. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
